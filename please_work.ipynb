{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "714367c0-94b8-44a0-8b2d-a314a6df9fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00685528-1d7f-4b43-a9fa-03c5512ac5e4",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e63c692-5f04-4064-9327-2ca6659377ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torchinfo\n",
    "import optuna\n",
    "\n",
    "import nndl.models.CNN as cnn\n",
    "import nndl.models.CNNLSTM as clstm\n",
    "import nndl.models.GRU as gru\n",
    "import nndl.utils as utils\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3291375a-0757-46bd-912c-214c03d2f302",
   "metadata": {},
   "source": [
    "# **Load data from localhost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c22e93-a467-4574-864d-205dd29910a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115, 22, 1000)\n",
      "(2115, 22, 1000)\n",
      "(443, 22, 1000)\n",
      "[2 3 0 ... 3 3 2]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load(\"./project_data/X_test.npy\")\n",
    "y_test = np.load(\"./project_data/y_test.npy\") - 769\n",
    "person_train_valid = np.load(\"./project_data/person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"./project_data/X_train_valid.npy\")\n",
    "print(X_train_valid.shape)\n",
    "y_train_valid = np.load(\"./project_data/y_train_valid.npy\") - 769\n",
    "person_test = np.load(\"./project_data/person_test.npy\")\n",
    "\n",
    "print(X_train_valid.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cc5ab2-0755-451d-b091-4a85f2053a53",
   "metadata": {},
   "source": [
    "# **Data Prep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "123553f6-97ae-4903-b473-5fa82a794113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOME torch.Size([2115, 22, 1000])\n",
      "subject counts:  [210, 209, 211, 215, 216, 215, 208, 205, 214]\n",
      "subject count sum:  1903\n",
      "\n",
      "subject 0\n",
      "Shape of X after trimming: torch.Size([210, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([210, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([420, 22, 400])\n",
      "torch.Size([420, 1])\n",
      "torch.Size([210, 1])\n",
      "torch.Size([630, 1])\n",
      "torch.Size([210, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([840, 22, 400])\n",
      "Shape of Y: torch.Size([840])\n",
      "Shape of X after channel dropout torch.Size([1680, 22, 400])\n",
      "Shape of Y: torch.Size([1680])\n",
      "Shape of X after reverse torch.Size([2808, 22, 400])\n",
      "Shape of Y: torch.Size([2808])\n",
      "\n",
      "subject 1\n",
      "Shape of X after trimming: torch.Size([209, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([209, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([418, 22, 400])\n",
      "torch.Size([418, 1])\n",
      "torch.Size([209, 1])\n",
      "torch.Size([627, 1])\n",
      "torch.Size([209, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([836, 22, 400])\n",
      "Shape of Y: torch.Size([836])\n",
      "Shape of X after channel dropout torch.Size([1672, 22, 400])\n",
      "Shape of Y: torch.Size([1672])\n",
      "Shape of X after reverse torch.Size([2858, 22, 400])\n",
      "Shape of Y: torch.Size([2858])\n",
      "\n",
      "subject 2\n",
      "Shape of X after trimming: torch.Size([211, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([211, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([422, 22, 400])\n",
      "torch.Size([422, 1])\n",
      "torch.Size([211, 1])\n",
      "torch.Size([633, 1])\n",
      "torch.Size([211, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([844, 22, 400])\n",
      "Shape of Y: torch.Size([844])\n",
      "Shape of X after channel dropout torch.Size([1688, 22, 400])\n",
      "Shape of Y: torch.Size([1688])\n",
      "Shape of X after reverse torch.Size([2866, 22, 400])\n",
      "Shape of Y: torch.Size([2866])\n",
      "\n",
      "subject 3\n",
      "Shape of X after trimming: torch.Size([215, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([215, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([430, 22, 400])\n",
      "torch.Size([430, 1])\n",
      "torch.Size([215, 1])\n",
      "torch.Size([645, 1])\n",
      "torch.Size([215, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([860, 22, 400])\n",
      "Shape of Y: torch.Size([860])\n",
      "Shape of X after channel dropout torch.Size([1720, 22, 400])\n",
      "Shape of Y: torch.Size([1720])\n",
      "Shape of X after reverse torch.Size([2906, 22, 400])\n",
      "Shape of Y: torch.Size([2906])\n",
      "\n",
      "subject 4\n",
      "Shape of X after trimming: torch.Size([216, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([216, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([432, 22, 400])\n",
      "torch.Size([432, 1])\n",
      "torch.Size([216, 1])\n",
      "torch.Size([648, 1])\n",
      "torch.Size([216, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([864, 22, 400])\n",
      "Shape of Y: torch.Size([864])\n",
      "Shape of X after channel dropout torch.Size([1728, 22, 400])\n",
      "Shape of Y: torch.Size([1728])\n",
      "Shape of X after reverse torch.Size([2931, 22, 400])\n",
      "Shape of Y: torch.Size([2931])\n",
      "\n",
      "subject 5\n",
      "Shape of X after trimming: torch.Size([215, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([215, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([430, 22, 400])\n",
      "torch.Size([430, 1])\n",
      "torch.Size([215, 1])\n",
      "torch.Size([645, 1])\n",
      "torch.Size([215, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([860, 22, 400])\n",
      "Shape of Y: torch.Size([860])\n",
      "Shape of X after channel dropout torch.Size([1720, 22, 400])\n",
      "Shape of Y: torch.Size([1720])\n",
      "Shape of X after reverse torch.Size([2924, 22, 400])\n",
      "Shape of Y: torch.Size([2924])\n",
      "\n",
      "subject 6\n",
      "Shape of X after trimming: torch.Size([208, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([208, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([416, 22, 400])\n",
      "torch.Size([416, 1])\n",
      "torch.Size([208, 1])\n",
      "torch.Size([624, 1])\n",
      "torch.Size([208, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([832, 22, 400])\n",
      "Shape of Y: torch.Size([832])\n",
      "Shape of X after channel dropout torch.Size([1664, 22, 400])\n",
      "Shape of Y: torch.Size([1664])\n",
      "Shape of X after reverse torch.Size([2790, 22, 400])\n",
      "Shape of Y: torch.Size([2790])\n",
      "\n",
      "subject 7\n",
      "Shape of X after trimming: torch.Size([205, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([205, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([410, 22, 400])\n",
      "torch.Size([410, 1])\n",
      "torch.Size([205, 1])\n",
      "torch.Size([615, 1])\n",
      "torch.Size([205, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([820, 22, 400])\n",
      "Shape of Y: torch.Size([820])\n",
      "Shape of X after channel dropout torch.Size([1640, 22, 400])\n",
      "Shape of Y: torch.Size([1640])\n",
      "Shape of X after reverse torch.Size([2807, 22, 400])\n",
      "Shape of Y: torch.Size([2807])\n",
      "\n",
      "subject 8\n",
      "Shape of X after trimming: torch.Size([214, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([214, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([428, 22, 400])\n",
      "torch.Size([428, 1])\n",
      "torch.Size([214, 1])\n",
      "torch.Size([642, 1])\n",
      "torch.Size([214, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([856, 22, 400])\n",
      "Shape of Y: torch.Size([856])\n",
      "Shape of X after channel dropout torch.Size([1712, 22, 400])\n",
      "Shape of Y: torch.Size([1712])\n",
      "Shape of X after reverse torch.Size([2933, 22, 400])\n",
      "Shape of Y: torch.Size([2933])\n",
      "torch.Size([212, 22, 1000])\n",
      "val counts:  [27, 27, 25, 19, 19, 21, 30, 27, 17]\n",
      "val count sum:  212\n",
      "\n",
      "subject 0\n",
      "Shape of X after trimming: torch.Size([27, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([27, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([54, 22, 400])\n",
      "torch.Size([54, 1])\n",
      "torch.Size([27, 1])\n",
      "torch.Size([81, 1])\n",
      "torch.Size([27, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([108, 22, 400])\n",
      "Shape of Y: torch.Size([108])\n",
      "Shape of X after channel dropout torch.Size([216, 22, 400])\n",
      "Shape of Y: torch.Size([216])\n",
      "Shape of X after reverse torch.Size([367, 22, 400])\n",
      "Shape of Y: torch.Size([367])\n",
      "\n",
      "subject 1\n",
      "Shape of X after trimming: torch.Size([27, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([27, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([54, 22, 400])\n",
      "torch.Size([54, 1])\n",
      "torch.Size([27, 1])\n",
      "torch.Size([81, 1])\n",
      "torch.Size([27, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([108, 22, 400])\n",
      "Shape of Y: torch.Size([108])\n",
      "Shape of X after channel dropout torch.Size([216, 22, 400])\n",
      "Shape of Y: torch.Size([216])\n",
      "Shape of X after reverse torch.Size([378, 22, 400])\n",
      "Shape of Y: torch.Size([378])\n",
      "\n",
      "subject 2\n",
      "Shape of X after trimming: torch.Size([25, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([25, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([50, 22, 400])\n",
      "torch.Size([50, 1])\n",
      "torch.Size([25, 1])\n",
      "torch.Size([75, 1])\n",
      "torch.Size([25, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([100, 22, 400])\n",
      "Shape of Y: torch.Size([100])\n",
      "Shape of X after channel dropout torch.Size([200, 22, 400])\n",
      "Shape of Y: torch.Size([200])\n",
      "Shape of X after reverse torch.Size([343, 22, 400])\n",
      "Shape of Y: torch.Size([343])\n",
      "\n",
      "subject 3\n",
      "Shape of X after trimming: torch.Size([19, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([19, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([38, 22, 400])\n",
      "torch.Size([38, 1])\n",
      "torch.Size([19, 1])\n",
      "torch.Size([57, 1])\n",
      "torch.Size([19, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([76, 22, 400])\n",
      "Shape of Y: torch.Size([76])\n",
      "Shape of X after channel dropout torch.Size([152, 22, 400])\n",
      "Shape of Y: torch.Size([152])\n",
      "Shape of X after reverse torch.Size([259, 22, 400])\n",
      "Shape of Y: torch.Size([259])\n",
      "\n",
      "subject 4\n",
      "Shape of X after trimming: torch.Size([19, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([19, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([38, 22, 400])\n",
      "torch.Size([38, 1])\n",
      "torch.Size([19, 1])\n",
      "torch.Size([57, 1])\n",
      "torch.Size([19, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([76, 22, 400])\n",
      "Shape of Y: torch.Size([76])\n",
      "Shape of X after channel dropout torch.Size([152, 22, 400])\n",
      "Shape of Y: torch.Size([152])\n",
      "Shape of X after reverse torch.Size([248, 22, 400])\n",
      "Shape of Y: torch.Size([248])\n",
      "\n",
      "subject 5\n",
      "Shape of X after trimming: torch.Size([21, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([21, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([42, 22, 400])\n",
      "torch.Size([42, 1])\n",
      "torch.Size([21, 1])\n",
      "torch.Size([63, 1])\n",
      "torch.Size([21, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([84, 22, 400])\n",
      "Shape of Y: torch.Size([84])\n",
      "Shape of X after channel dropout torch.Size([168, 22, 400])\n",
      "Shape of Y: torch.Size([168])\n",
      "Shape of X after reverse torch.Size([290, 22, 400])\n",
      "Shape of Y: torch.Size([290])\n",
      "\n",
      "subject 6\n",
      "Shape of X after trimming: torch.Size([30, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([30, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([60, 22, 400])\n",
      "torch.Size([60, 1])\n",
      "torch.Size([30, 1])\n",
      "torch.Size([90, 1])\n",
      "torch.Size([30, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([120, 22, 400])\n",
      "Shape of Y: torch.Size([120])\n",
      "Shape of X after channel dropout torch.Size([240, 22, 400])\n",
      "Shape of Y: torch.Size([240])\n",
      "Shape of X after reverse torch.Size([416, 22, 400])\n",
      "Shape of Y: torch.Size([416])\n",
      "\n",
      "subject 7\n",
      "Shape of X after trimming: torch.Size([27, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([27, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([54, 22, 400])\n",
      "torch.Size([54, 1])\n",
      "torch.Size([27, 1])\n",
      "torch.Size([81, 1])\n",
      "torch.Size([27, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([108, 22, 400])\n",
      "Shape of Y: torch.Size([108])\n",
      "Shape of X after channel dropout torch.Size([216, 22, 400])\n",
      "Shape of Y: torch.Size([216])\n",
      "Shape of X after reverse torch.Size([360, 22, 400])\n",
      "Shape of Y: torch.Size([360])\n",
      "\n",
      "subject 8\n",
      "Shape of X after trimming: torch.Size([17, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([17, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([34, 22, 400])\n",
      "torch.Size([34, 1])\n",
      "torch.Size([17, 1])\n",
      "torch.Size([51, 1])\n",
      "torch.Size([17, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([68, 22, 400])\n",
      "Shape of Y: torch.Size([68])\n",
      "Shape of X after channel dropout torch.Size([136, 22, 400])\n",
      "Shape of Y: torch.Size([136])\n",
      "Shape of X after reverse torch.Size([229, 22, 400])\n",
      "Shape of Y: torch.Size([229])\n",
      "torch.Size([443, 22, 1000])\n",
      "test counts:  [50, 50, 50, 50, 47, 49, 50, 50, 47]\n",
      "test count sum:  443\n",
      "\n",
      "subject 0\n",
      "Shape of X after trimming: torch.Size([50, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([50, 22, 400])\n",
      "\n",
      "subject 1\n",
      "Shape of X after trimming: torch.Size([50, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([50, 22, 400])\n",
      "\n",
      "subject 2\n",
      "Shape of X after trimming: torch.Size([50, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([50, 22, 400])\n",
      "\n",
      "subject 3\n",
      "Shape of X after trimming: torch.Size([50, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([50, 22, 400])\n",
      "\n",
      "subject 4\n",
      "Shape of X after trimming: torch.Size([47, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([47, 22, 400])\n",
      "\n",
      "subject 5\n",
      "Shape of X after trimming: torch.Size([49, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([49, 22, 400])\n",
      "\n",
      "subject 6\n",
      "Shape of X after trimming: torch.Size([50, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([50, 22, 400])\n",
      "\n",
      "subject 7\n",
      "Shape of X after trimming: torch.Size([50, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([50, 22, 400])\n",
      "\n",
      "subject 8\n",
      "Shape of X after trimming: torch.Size([47, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([47, 22, 400])\n",
      "Prepping Training Data\n",
      "Shape of X after trimming: torch.Size([1903, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([1903, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([3806, 22, 400])\n",
      "torch.Size([3806, 1])\n",
      "torch.Size([1903, 1])\n",
      "torch.Size([5709, 1])\n",
      "torch.Size([1903, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([7612, 22, 400])\n",
      "Shape of Y: torch.Size([7612])\n",
      "Shape of X after channel dropout torch.Size([15224, 22, 400])\n",
      "Shape of Y: torch.Size([15224])\n",
      "Shape of X after reverse torch.Size([27353, 22, 400])\n",
      "Shape of Y: torch.Size([27353])\n",
      "\n",
      "Prepping Validation Data\n",
      "Shape of X after trimming: torch.Size([212, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([212, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([424, 22, 400])\n",
      "torch.Size([424, 1])\n",
      "torch.Size([212, 1])\n",
      "torch.Size([636, 1])\n",
      "torch.Size([212, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([848, 22, 400])\n",
      "Shape of Y: torch.Size([848])\n",
      "Shape of X after channel dropout torch.Size([1696, 22, 400])\n",
      "Shape of Y: torch.Size([1696])\n",
      "Shape of X after reverse torch.Size([3056, 22, 400])\n",
      "Shape of Y: torch.Size([3056])\n",
      "\n",
      "Prepping Test Data\n",
      "Shape of X after trimming: torch.Size([443, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([443, 22, 400])\n",
      "\n",
      "FINISHED PREP\n",
      "\n",
      "Final shape of training set: torch.Size([27353, 22, 400])\n",
      "Final shape of validation set: torch.Size([3056, 22, 400])\n",
      "Final shape of test set: torch.Size([443, 22, 400])\n",
      "TRAIN_DATA 137\n",
      "VALID_DATA 16\n",
      "TEST_DATA 3\n"
     ]
    }
   ],
   "source": [
    "def data_prep(X,y,sub_sample,average,noise,channel_dropout,time_reverse):\n",
    "\n",
    "    total_X = None\n",
    "    total_y = None\n",
    "    X = X[:,:,0:800]\n",
    "    print('Shape of X after trimming:',X.shape)\n",
    "\n",
    "    X_max, _ = torch.max(X.view(X.size(0), X.size(1), -1, sub_sample), axis=3)\n",
    "\n",
    "\n",
    "    total_X = X_max\n",
    "    total_y = y\n",
    "    print('Shape of X after maxpooling:',total_X.shape)\n",
    "\n",
    "    X_average = torch.mean(X.view(X.size(0), X.size(1), -1, average), axis=3)\n",
    "    X_average = X_average + torch.normal(0.0, 0.5, X_average.shape)\n",
    "\n",
    "    total_X = torch.cat((total_X, X_average), dim=0)\n",
    "    total_y = torch.cat((total_y, y))\n",
    "    print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
    "\n",
    "    for i in range(sub_sample):\n",
    "\n",
    "        X_subsample = X[:, :, i::sub_sample] + \\\n",
    "                            (torch.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
    "\n",
    "        total_X = torch.cat((total_X, X_subsample), dim=0)\n",
    "        print(total_y.view(-1,1).shape)\n",
    "        print(y.view(-1,1).shape)\n",
    "        total_y = torch.cat((total_y, y))\n",
    "\n",
    "    print('Shape of X after subsampling and concatenating:',total_X.shape)\n",
    "    print('Shape of Y:',total_y.shape)\n",
    "\n",
    "    if channel_dropout != 0:\n",
    "        mask = (torch.rand(total_X.shape[0], total_X.shape[1]) >= channel_dropout).unsqueeze(2)\n",
    "        X_dropout = mask * total_X\n",
    "        total_X = torch.cat((total_X, X_dropout))\n",
    "        total_y = torch.cat((total_y, total_y))\n",
    "\n",
    "        print(f'Shape of X after channel dropout {total_X.shape}')\n",
    "        print(f'Shape of Y: {total_y.shape}')\n",
    "\n",
    "    if time_reverse != 0:\n",
    "        mask = (torch.rand(total_X.shape[0]) >= time_reverse)\n",
    "        X_reverse = torch.flip((total_X[mask]), [2])\n",
    "        total_X = torch.cat((total_X, X_reverse))\n",
    "        total_y = torch.cat((total_y, total_y[mask]))\n",
    "\n",
    "        print(f'Shape of X after reverse {total_X.shape}')\n",
    "        print(f'Shape of Y: {total_y.shape}')\n",
    "\n",
    "\n",
    "    return total_X,total_y\n",
    "    return total_X,total_y\n",
    "\n",
    "\n",
    "def test_data_prep(X):\n",
    "\n",
    "    total_X = None\n",
    "\n",
    "    X = X[:,:,0:800]\n",
    "    print('Shape of X after trimming:', X.shape)\n",
    "    X_max, _ = torch.max(X.view(X.size(0), X.size(1), -1, 2), axis=3)\n",
    "\n",
    "    total_X = X_max\n",
    "    print('Shape of X after maxpooling:',total_X.shape)\n",
    "\n",
    "    return total_X\n",
    "\n",
    "input_size = 22\n",
    "hidden_size = 256\n",
    "num_layers = 10\n",
    "num_classes = 4\n",
    "learning_rate = 1e-4\n",
    "batch_size = 200\n",
    "num_epochs = 100\n",
    "dropout = 0.3\n",
    "\n",
    "folds = 10\n",
    "split_seed = 1\n",
    "subsample = 2\n",
    "average = 2\n",
    "channel_dropout = 0.2\n",
    "time_reverse = 0.3\n",
    "noise = True\n",
    "\n",
    "'''\n",
    "This was the old data prep.\n",
    "The code below is just split up.\n",
    "Split data, then split up X_train, X_val, X_test by subject and create dataloaders\n",
    "Then dataprep and dataloader is performed for x_train etc\n",
    "kept in case of error then can go back\n",
    "i could have put them in lists\n",
    "'''\n",
    "'''\n",
    "X_train_valid = torch.Tensor(X_train_valid)\n",
    "y_train_valid = torch.Tensor(y_train_valid)\n",
    "\n",
    "print(f'SOME {X_train_valid.shape}')\n",
    "indices = torch.randperm(X_train_valid.shape[0])\n",
    "split_idx = int(X_train_valid.shape[0] * ((folds-1)/folds))\n",
    "X_train, X_valid = X_train_valid[indices[:split_idx]], X_train_valid[indices[split_idx:]]\n",
    "y_train, y_valid = y_train_valid[indices[:split_idx]], y_train_valid[indices[split_idx:]]\n",
    "X_test, y_test = torch.Tensor(X_test), torch.Tensor(y_test)\n",
    "\n",
    "print('Prepping Training Data')\n",
    "X_train, y_train = data_prep(X_train, y_train, subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nPrepping Validation Data')\n",
    "X_valid, y_valid = data_prep(X_valid, y_valid, subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nPrepping Test Data')\n",
    "X_test = test_data_prep(X_test)\n",
    "print('\\nFINISHED PREP\\n')\n",
    "\n",
    "print('Final shape of training set:', X_train.shape)\n",
    "print('Final shape of validation set:', X_valid.shape)\n",
    "print('Final shape of test set:', X_test.shape)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_valid, y_valid), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f'TRAIN_DATA {len(train_loader)}\\nVALID_DATA {len(val_loader)}\\nTEST_DATA {len(test_loader)}')\n",
    "'''\n",
    "\n",
    "X_train_valid = torch.Tensor(X_train_valid)\n",
    "y_train_valid = torch.Tensor(y_train_valid)\n",
    "\n",
    "print(f'SOME {X_train_valid.shape}')\n",
    "indices = torch.randperm(X_train_valid.shape[0])\n",
    "#print(indices)\n",
    "split_idx = int(X_train_valid.shape[0] * ((folds-1)/folds))\n",
    "#print(split_idx)\n",
    "X_train, X_valid = X_train_valid[indices[:split_idx]], X_train_valid[indices[split_idx:]]\n",
    "y_train, y_valid = y_train_valid[indices[:split_idx]], y_train_valid[indices[split_idx:]]\n",
    "X_test, y_test = torch.Tensor(X_test), torch.Tensor(y_test)\n",
    "\n",
    "person_train_valid, person_test = torch.Tensor(person_train_valid), torch.Tensor(person_test)\n",
    "person_train, person_valid = person_train_valid[indices[:split_idx]], person_train_valid[indices[split_idx:]]\n",
    "\n",
    "#check it matches\n",
    "'''\n",
    "index_zero = (indices == 0).nonzero(as_tuple=False) #index in indices that hold index 0 in X_train_valid and person_train_valid\n",
    "print(index_zero)\n",
    "print(indices[index_zero])\n",
    "if index_zero > 1902: #in validation\n",
    "  print(X_train_valid[0])\n",
    "  print(X_train[index_zero - 1903])\n",
    "  print(person_train[index_zero - 1903])\n",
    "  print(person_train_valid[0])\n",
    "else:\n",
    "  print(X_train_valid[0])\n",
    "  print(X_train[index_zero])\n",
    "  print(person_train[index_zero])\n",
    "  print(person_train_valid[0])\n",
    "'''\n",
    "\n",
    "################################################\n",
    "#seperate X_train by subject using person_train\n",
    "################################################\n",
    "\n",
    "s_train = [[], [], [], [], [], [], [], [], []]\n",
    "s_y_train = [[], [], [], [], [], [], [], [], []]\n",
    "count_train = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "for (i, j) in zip(person_train, range(len(person_train))):\n",
    "  #i is a np.darray from subject_train, i[0] gives us the subject\n",
    "  #j is the index of i in subject_train that corresponds to the index in subject_train\n",
    "  s_train[int(i[0])].append(X_train[j])\n",
    "  s_y_train[int(i[0])].append(y_train[j])\n",
    "\n",
    "  #for length check\n",
    "  count_train[int(i[0])]+=1\n",
    "\n",
    "print('subject counts: ', count_train)\n",
    "print('subject count sum: ', sum(count_train))\n",
    "\n",
    "#lebron\n",
    "for (i, j, k) in zip(count_train, s_train, s_y_train):\n",
    "  if i != len(j) or i != len(k):\n",
    "    print(\"length issue\")\n",
    "\n",
    "\n",
    "print('\\nsubject 0')\n",
    "s0_train, s0_y_train = data_prep(torch.Tensor(np.asarray(s_train[0])), torch.Tensor(np.asarray(s_y_train[0])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nsubject 1')\n",
    "s1_train, s1_y_train = data_prep(torch.Tensor(np.asarray(s_train[1])), torch.Tensor(np.asarray(s_y_train[1])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nsubject 2')\n",
    "s2_train, s2_y_train = data_prep(torch.Tensor(np.asarray(s_train[2])), torch.Tensor(np.asarray(s_y_train[2])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nsubject 3')\n",
    "s3_train, s3_y_train = data_prep(torch.Tensor(np.asarray(s_train[3])), torch.Tensor(np.asarray(s_y_train[3])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nsubject 4')\n",
    "s4_train, s4_y_train = data_prep(torch.Tensor(np.asarray(s_train[4])), torch.Tensor(np.asarray(s_y_train[4])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nsubject 5')\n",
    "s5_train, s5_y_train = data_prep(torch.Tensor(np.asarray(s_train[5])), torch.Tensor(np.asarray(s_y_train[5])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nsubject 6')\n",
    "s6_train, s6_y_train = data_prep(torch.Tensor(np.asarray(s_train[6])), torch.Tensor(np.asarray(s_y_train[6])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nsubject 7')\n",
    "s7_train, s7_y_train = data_prep(torch.Tensor(np.asarray(s_train[7])), torch.Tensor(np.asarray(s_y_train[7])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nsubject 8')\n",
    "s8_train, s8_y_train = data_prep(torch.Tensor(np.asarray(s_train[8])), torch.Tensor(np.asarray(s_y_train[8])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "\n",
    "#############################################\n",
    "#seperate X_val by subject using person_valid\n",
    "#############################################\n",
    "print(X_valid.shape)\n",
    "\n",
    "s_valid = [[], [], [], [], [], [], [], [], []]\n",
    "s_y_valid = [[], [], [], [], [], [], [], [], []]\n",
    "count_val = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "for (i, j) in zip(person_valid, range(len(person_valid))):\n",
    "  #i is a np.darray from subject_train, i[0] gives us the subject\n",
    "  #j is the index of i in subject_train that corresponds to the index in subject_train\n",
    "  s_valid[int(i[0])].append(X_valid[j])\n",
    "  s_y_valid[int(i[0])].append(y_valid[j])\n",
    "\n",
    "  #for length check\n",
    "  count_val[int(i[0])]+=1\n",
    "\n",
    "print('val counts: ', count_val)\n",
    "print('val count sum: ', sum(count_val))\n",
    "\n",
    "#lebron\n",
    "for (i, j, k) in zip(count_val, s_valid, s_y_valid):\n",
    "  if i != len(j) or i != len(k):\n",
    "    print(\"length issue\")\n",
    "\n",
    "print('\\nsubject 0')\n",
    "s0_valid, s0_y_valid = data_prep(torch.Tensor(np.asarray(s_valid[0])), torch.Tensor(np.asarray(s_y_valid[0])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nsubject 1')\n",
    "s1_valid, s1_y_valid = data_prep(torch.Tensor(np.asarray(s_valid[1])), torch.Tensor(np.asarray(s_y_valid[1])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nsubject 2')\n",
    "s2_valid, s2_y_valid = data_prep(torch.Tensor(np.asarray(s_valid[2])), torch.Tensor(np.asarray(s_y_valid[2])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nsubject 3')\n",
    "s3_valid, s3_y_valid = data_prep(torch.Tensor(np.asarray(s_valid[3])), torch.Tensor(np.asarray(s_y_valid[3])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nsubject 4')\n",
    "s4_valid, s4_y_valid = data_prep(torch.Tensor(np.asarray(s_valid[4])), torch.Tensor(np.asarray(s_y_valid[4])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nsubject 5')\n",
    "s5_valid, s5_y_valid = data_prep(torch.Tensor(np.asarray(s_valid[5])), torch.Tensor(np.asarray(s_y_valid[5])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nsubject 6')\n",
    "s6_valid, s6_y_valid = data_prep(torch.Tensor(np.asarray(s_valid[6])), torch.Tensor(np.asarray(s_y_valid[6])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nsubject 7')\n",
    "s7_valid, s7_y_valid = data_prep(torch.Tensor(np.asarray(s_valid[7])), torch.Tensor(np.asarray(s_y_valid[7])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nsubject 8')\n",
    "s8_valid, s8_y_valid = data_prep(torch.Tensor(np.asarray(s_valid[8])), torch.Tensor(np.asarray(s_y_valid[8])), subsample, average, noise, channel_dropout, time_reverse)\n",
    "\n",
    "#############################################\n",
    "#seperate X_test by subject using person_test\n",
    "#############################################\n",
    "print(X_test.shape)\n",
    "\n",
    "s_test = [[], [], [], [], [], [], [], [], []]\n",
    "s_y_test = [[], [], [], [], [], [], [], [], []]\n",
    "count_test = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "for (i, j) in zip(person_test, range(len(person_test))):\n",
    "  #i is a np.darray from person_test, i[0] gives us the subject\n",
    "  #j is the index of i in person_test that corresponds to the index in X_test\n",
    "  s_test[int(i[0])].append(X_test[j])\n",
    "  s_y_test[int(i[0])].append(y_test[j])\n",
    "\n",
    "  #for length check\n",
    "  count_test[int(i[0])]+=1\n",
    "\n",
    "print('test counts: ', count_test)\n",
    "print('test count sum: ', sum(count_test))\n",
    "\n",
    "#lebron length check\n",
    "for (i, j, k) in zip(count_test, s_test, s_y_test):\n",
    "  if i != len(j) or i != len(k):\n",
    "    print(\"length issue\")\n",
    "\n",
    "#Look in my eyes, tell me your tale Do you see the road, the map to my soul? Look, tell me the signs whenever the smoke clear out of my face Am I picture-perfect or do I look fried?\n",
    "print('\\nsubject 0')\n",
    "s0_test, s0_y_test = test_data_prep(torch.Tensor(np.asarray(s_test[0]))), torch.Tensor(np.asarray(s_y_test[0]))\n",
    "print('\\nsubject 1')\n",
    "s1_test, s1_y_test = test_data_prep(torch.Tensor(np.asarray(s_test[1]))), torch.Tensor(np.asarray(s_y_test[1]))\n",
    "print('\\nsubject 2')\n",
    "s2_test, s2_y_test = test_data_prep(torch.Tensor(np.asarray(s_test[2]))), torch.Tensor(np.asarray(s_y_test[2]))\n",
    "print('\\nsubject 3')\n",
    "s3_test, s3_y_test = test_data_prep(torch.Tensor(np.asarray(s_test[3]))), torch.Tensor(np.asarray(s_y_test[3]))\n",
    "print('\\nsubject 4')\n",
    "s4_test, s4_y_test = test_data_prep(torch.Tensor(np.asarray(s_test[4]))), torch.Tensor(np.asarray(s_y_test[4]))\n",
    "print('\\nsubject 5')\n",
    "s5_test, s5_y_test = test_data_prep(torch.Tensor(np.asarray(s_test[5]))), torch.Tensor(np.asarray(s_y_test[5]))\n",
    "print('\\nsubject 6')\n",
    "s6_test, s6_y_test = test_data_prep(torch.Tensor(np.asarray(s_test[6]))), torch.Tensor(np.asarray(s_y_test[6]))\n",
    "print('\\nsubject 7')\n",
    "s7_test, s7_y_test = test_data_prep(torch.Tensor(np.asarray(s_test[7]))), torch.Tensor(np.asarray(s_y_test[7]))\n",
    "print('\\nsubject 8')\n",
    "s8_test, s8_y_test = test_data_prep(torch.Tensor(np.asarray(s_test[8]))), torch.Tensor(np.asarray(s_y_test[8]))\n",
    "\n",
    "#############################\n",
    "#Generate Subject DataLoader#\n",
    "#############################\n",
    "\n",
    "s0_train_loader = DataLoader(TensorDataset(s0_train, s0_y_train), batch_size=batch_size, shuffle=True)\n",
    "s0_val_loader = DataLoader(TensorDataset(s0_valid, s0_y_valid), batch_size=batch_size, shuffle=True)\n",
    "s0_test_loader = DataLoader(TensorDataset(s0_test, s0_y_test), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "s1_train_loader = DataLoader(TensorDataset(s1_train, s1_y_train), batch_size=batch_size, shuffle=True)\n",
    "s1_val_loader = DataLoader(TensorDataset(s1_valid, s1_y_valid), batch_size=batch_size, shuffle=True)\n",
    "s1_test_loader = DataLoader(TensorDataset(s1_test, s1_y_test), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "s2_train_loader = DataLoader(TensorDataset(s2_train, s2_y_train), batch_size=batch_size, shuffle=True)\n",
    "s2_val_loader = DataLoader(TensorDataset(s2_valid, s2_y_valid), batch_size=batch_size, shuffle=True)\n",
    "s2_test_loader = DataLoader(TensorDataset(s2_test, s2_y_test), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "s3_train_loader = DataLoader(TensorDataset(s3_train, s3_y_train), batch_size=batch_size, shuffle=True)\n",
    "s3_val_loader = DataLoader(TensorDataset(s3_valid, s3_y_valid), batch_size=batch_size, shuffle=True)\n",
    "s3_test_loader = DataLoader(TensorDataset(s3_test, s3_y_test), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "s4_train_loader = DataLoader(TensorDataset(s4_train, s4_y_train), batch_size=batch_size, shuffle=True)\n",
    "s4_val_loader = DataLoader(TensorDataset(s4_valid, s4_y_valid), batch_size=batch_size, shuffle=True)\n",
    "s4_test_loader = DataLoader(TensorDataset(s4_test, s4_y_test), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "s5_train_loader = DataLoader(TensorDataset(s5_train, s5_y_train), batch_size=batch_size, shuffle=True)\n",
    "s5_val_loader = DataLoader(TensorDataset(s5_valid, s5_y_valid), batch_size=batch_size, shuffle=True)\n",
    "s5_test_loader = DataLoader(TensorDataset(s5_test, s5_y_test), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "s6_train_loader = DataLoader(TensorDataset(s6_train, s6_y_train), batch_size=batch_size, shuffle=True)\n",
    "s6_val_loader = DataLoader(TensorDataset(s6_valid, s6_y_valid), batch_size=batch_size, shuffle=True)\n",
    "s6_test_loader = DataLoader(TensorDataset(s6_test, s6_y_test), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "s7_train_loader = DataLoader(TensorDataset(s7_train, s7_y_train), batch_size=batch_size, shuffle=True)\n",
    "s7_val_loader = DataLoader(TensorDataset(s7_valid, s7_y_valid), batch_size=batch_size, shuffle=True)\n",
    "s7_test_loader = DataLoader(TensorDataset(s7_test, s7_y_test), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "s8_train_loader = DataLoader(TensorDataset(s8_train, s8_y_train), batch_size=batch_size, shuffle=True)\n",
    "s8_val_loader = DataLoader(TensorDataset(s8_valid, s8_y_valid), batch_size=batch_size, shuffle=True)\n",
    "s8_test_loader = DataLoader(TensorDataset(s8_test, s8_y_test), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "subject_train_loader = [s0_train_loader, s1_train_loader, s2_train_loader, s3_train_loader, s4_train_loader, s5_train_loader, s6_train_loader, s7_train_loader,  s8_train_loader]\n",
    "subject_val_loader = [s0_val_loader, s1_val_loader, s2_val_loader, s3_val_loader, s4_val_loader, s5_val_loader, s6_val_loader, s7_val_loader, s8_val_loader]\n",
    "subject_test_loader = [s0_test_loader, s1_test_loader, s2_test_loader, s3_test_loader, s4_test_loader, s5_test_loader, s6_test_loader, s7_test_loader, s8_test_loader]\n",
    "\n",
    "\n",
    "time_reverse = 0.2\n",
    "print('Prepping Training Data')\n",
    "X_train, y_train = data_prep(X_train, y_train, subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nPrepping Validation Data')\n",
    "X_valid, y_valid = data_prep(X_valid, y_valid, subsample, average, noise, channel_dropout, time_reverse)\n",
    "print('\\nPrepping Test Data')\n",
    "X_test = test_data_prep(X_test)\n",
    "print('\\nFINISHED PREP\\n')\n",
    "\n",
    "print('Final shape of training set:', X_train.shape)\n",
    "print('Final shape of validation set:', X_valid.shape)\n",
    "print('Final shape of test set:', X_test.shape)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_valid, y_valid), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f'TRAIN_DATA {len(train_loader)}\\nVALID_DATA {len(val_loader)}\\nTEST_DATA {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f83d9e-20b5-4620-a114-b302ea1d6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8c190b-1f35-468a-b6a2-9e132f10cac8",
   "metadata": {},
   "source": [
    "# **CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8f6cce6-daf5-4a9b-a798-8fd7d86eb3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6640a6-7de1-4142-9891-a94c848e8cb8",
   "metadata": {},
   "source": [
    "# **CNNLSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d1ac219-a26d-412c-9474-756913bd4f3a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.layer = layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        tmp = x.contiguous().view(-1, x.size(-1))\n",
    "        y = self.layer(tmp)\n",
    "        y = y.contiguous().view(x.size(0), -1, y.size(-1))\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_classes=4,\n",
    "                 hidden_dims=128,\n",
    "                 dropout=0.5,\n",
    "                 kernel_size=10,\n",
    "                 pool_kernel=5,\n",
    "                 time_bins=400,\n",
    "                 channels=22,\n",
    "                 depth=32):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "\n",
    "        self.height = np.sqrt(depth)\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=channels,\n",
    "                      out_channels=depth,\n",
    "                      kernel_size=kernel_size**2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(depth),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=depth,\n",
    "                      out_channels=depth * 2,\n",
    "                      kernel_size=kernel_size),\n",
    "            nn.ELU(),\n",
    "            nn.BatchNorm1d(depth * 2),\n",
    "            nn.MaxPool1d(kernel_size=pool_kernel),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=depth * 2,\n",
    "                      out_channels=depth * 4,\n",
    "                      kernel_size=kernel_size),\n",
    "            nn.ELU(),\n",
    "            nn.BatchNorm1d(depth * 4),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size=depth * 4,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=2,\n",
    "                            batch_first=True,\n",
    "                           bidirectional=True)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(input_size=hidden_size * 2,\n",
    "                            hidden_size=hidden_size // 2,\n",
    "                            num_layers=2,\n",
    "                            batch_first=True,\n",
    "                           bidirectional=True)\n",
    "        \n",
    "        self.dense = TimeDistributed(nn.Linear(in_features=hidden_size,\n",
    "                                               out_features=hidden_size))\n",
    "        self.affine = nn.Linear(in_features=hidden_size,\n",
    "                                out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.affine(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c4add8-40c4-4275-83cd-1dd049ed38a8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN_LSTM                                 [64, 4]                   --\n",
       "├─Sequential: 1-1                        [64, 32, 301]             --\n",
       "│    └─Conv1d: 2-1                       [64, 32, 301]             70,432\n",
       "│    └─ReLU: 2-2                         [64, 32, 301]             --\n",
       "│    └─BatchNorm1d: 2-3                  [64, 32, 301]             64\n",
       "│    └─Dropout: 2-4                      [64, 32, 301]             --\n",
       "├─Sequential: 1-2                        [64, 64, 58]              --\n",
       "│    └─Conv1d: 2-5                       [64, 64, 292]             20,544\n",
       "│    └─ELU: 2-6                          [64, 64, 292]             --\n",
       "│    └─BatchNorm1d: 2-7                  [64, 64, 292]             128\n",
       "│    └─MaxPool1d: 2-8                    [64, 64, 58]              --\n",
       "│    └─Dropout: 2-9                      [64, 64, 58]              --\n",
       "├─Sequential: 1-3                        [64, 128, 49]             --\n",
       "│    └─Conv1d: 2-10                      [64, 128, 49]             82,048\n",
       "│    └─ELU: 2-11                         [64, 128, 49]             --\n",
       "│    └─BatchNorm1d: 2-12                 [64, 128, 49]             256\n",
       "│    └─Dropout: 2-13                     [64, 128, 49]             --\n",
       "├─LSTM: 1-4                              [64, 49, 512]             2,367,488\n",
       "├─LSTM: 1-5                              [64, 49, 256]             1,052,672\n",
       "├─TimeDistributed: 1-6                   [64, 49, 256]             --\n",
       "│    └─Linear: 2-14                      [3136, 256]               65,792\n",
       "├─Linear: 1-7                            [64, 4]                   1,028\n",
       "==========================================================================================\n",
       "Total params: 3,660,452\n",
       "Trainable params: 3,660,452\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 12.93\n",
       "==========================================================================================\n",
       "Input size (MB): 2.25\n",
       "Forward/backward pass size (MB): 61.11\n",
       "Params size (MB): 14.64\n",
       "Estimated Total Size (MB): 78.01\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clstm = CNN_LSTM().to(device)\n",
    "torchinfo.summary(clstm, input_size=(batch_size, 22, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8d51039-e93a-4c62-8932-2a658bfeb1cb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.NAdam(clstm.parameters(), lr=0.0017, weight_decay=0.0008)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "032c45ba-c26e-44d1-9272-b117cc439183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'criterion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train_accuracies, val_accuracies \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mtrain_model(model\u001b[38;5;241m=\u001b[39mclstm,\n\u001b[0;32m----> 2\u001b[0m                                                      criterion\u001b[38;5;241m=\u001b[39m\u001b[43mcriterion\u001b[49m,\n\u001b[1;32m      3\u001b[0m                                                      optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m      4\u001b[0m                                                      scheduler\u001b[38;5;241m=\u001b[39mscheduler,\n\u001b[1;32m      5\u001b[0m                                                      train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[1;32m      6\u001b[0m                                                      val_loader\u001b[38;5;241m=\u001b[39mval_loader,\n\u001b[1;32m      7\u001b[0m                                                      num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs,\n\u001b[1;32m      8\u001b[0m                                                      learning\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m                                                      device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     10\u001b[0m                                                      trial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'criterion' is not defined"
     ]
    }
   ],
   "source": [
    "train_accuracies, val_accuracies = utils.train_model(model=clstm,\n",
    "                                                     criterion=criterion,\n",
    "                                                     optimizer=optimizer,\n",
    "                                                     scheduler=scheduler,\n",
    "                                                     train_loader=train_loader,\n",
    "                                                     val_loader=val_loader,\n",
    "                                                     num_epochs=num_epochs,\n",
    "                                                     learning=False,\n",
    "                                                     device=device,\n",
    "                                                     trial=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89533fb8-8ed6-43f6-82f6-9e3ef67a0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num_epochs = 2\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b359f656-217a-4af9-ad64-e774f83bc3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "utils.test_model(clstm, test_loader)\n",
    "end_time = time.time()\n",
    "\n",
    "# hours = (optim_end - start_time) // 3600\n",
    "# minutes = ((optim_end - start_time) % 3600) // 60\n",
    "# seconds = (optim_end - start_time) % 60\n",
    "\n",
    "# print(f'time to train hyperparameters: \\\n",
    "# {hours} hours, \\\n",
    "# {minutes} minutes, \\\n",
    "# {int(seconds)} seconds')\n",
    "\n",
    "# print(f'time to train model: \\\n",
    "# {hours} hours, \\\n",
    "# {minutes} minutes, \\\n",
    "# {int(seconds)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "668a15c3-fabe-420e-8bd4-1a7c2895ec74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m clstm\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mgc\u001b[49m\u001b[38;5;241m.\u001b[39mcollect()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gc' is not defined"
     ]
    }
   ],
   "source": [
    "del clstm\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1ebe27-42e8-48d9-bdf1-659aa6c1c5fa",
   "metadata": {},
   "source": [
    "# **GRU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f70d547-87c2-461d-936c-53e44bcd8fd1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_classes=4,\n",
    "                 hidden_dims=128,\n",
    "                 num_layers=2,\n",
    "                 dropout=0.5,\n",
    "                 kernel=5,\n",
    "                 pool_kernel=2,\n",
    "                 time_bins=400,\n",
    "                 channels=22,\n",
    "                 depth=32):\n",
    "        super(GRU, self).__init__()\n",
    "\n",
    "        self.height = np.sqrt(depth)\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=channels,\n",
    "                      out_channels=depth,\n",
    "                      kernel_size=kernel**2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(depth),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=depth,\n",
    "                      out_channels=depth * 2,\n",
    "                      kernel_size=kernel**2),\n",
    "            nn.ELU(),\n",
    "            nn.BatchNorm1d(depth * 2),\n",
    "            nn.MaxPool1d(kernel_size=pool_kernel),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.gru1 = nn.GRU(input_size=depth * 2,\n",
    "                           hidden_size=hidden_dims // 2,\n",
    "                           num_layers=num_layers,\n",
    "                           bias=True,\n",
    "                           batch_first=True,\n",
    "                           bidirectional=True)\n",
    "        self.gru2 = nn.GRU(input_size=hidden_dims,\n",
    "                           hidden_size=hidden_dims,\n",
    "                           num_layers=num_layers,\n",
    "                           bias=True,\n",
    "                           batch_first=True,\n",
    "                           bidirectional=True)\n",
    "\n",
    "        self.dense = TimeDistributed(nn.Linear(in_features=hidden_dims * 2,\n",
    "                                               out_features=num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x, _ = self.gru1(x)\n",
    "        x, _ = self.gru2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x[:, -1, :]\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d113d43-7357-4e18-a32e-2c52e795aa18",
   "metadata": {},
   "source": [
    "# **GRU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd1a0720-94bd-4957-9a82-32a109714c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efe1347-7236-4dea-b07f-d72ce2828c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-12 04:26:00,055] A new study created in memory with name: no-name-cdb59883-9ade-490a-a5e1-2317c8c21212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with the following hyperparameters:\n",
      "---------------------------------------------\n",
      "    Batch Size:                         256\n",
      "    Hidden Dimensions:                  128\n",
      "    Optimizer:                          RMSprop\n",
      "        Learning Rate:                  0.0012745982073347295\n",
      "        Weight Decay:                   3.2801961858680135e-06\n",
      "        Momentum:                       0.8396885510134989\n",
      "    Model:                              GRU\n",
      "        Dropout:                        0.5180988344823947\n",
      "        (Block 1) Conv Kernel Size:     36\n",
      "        (Block 2-3) Conv Kernel Size:   6\n",
      "        Pool Kernel Size:               3\n",
      "        Depth:                          16\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dea1fe40729405f8196bd9ef2bd0dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = utils.learn_hyperparameters(X_train=X_train,\n",
    "                                     y_train=y_train,\n",
    "                                     X_valid=X_valid,\n",
    "                                     y_valid=y_valid,\n",
    "                                     model_name='GRU',\n",
    "                                     num_epochs=num_epochs,\n",
    "                                     trials=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee97a6-5921-4574-9f68-2e538adeb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gru.GRU(num_classes=4,\n",
    "              hidden_dims=params.get('hidden_dims'),\n",
    "              dropout=params.get('dropout'),\n",
    "              kernel=params.get('kernel'),\n",
    "              pool_kernel=params.get('pool_kernel'),\n",
    "              depth=params.get('depth'))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if params.get('optimizer_name') == 'RMSprop' or params.get('optimizer_name') == 'SGD':\n",
    "    optimizer = getattr(torch.optim, params.get('optimizer_name'))(model.parameters(),\n",
    "                                                                    lr=params.get('learning_rate'),\n",
    "                                                                    weight_decay=params.get('weight_decay'),\n",
    "                                                                    momentum=params.get('momentum'))\n",
    "else:\n",
    "    optimizer = getattr(torch.optim, params.get('optimizer_name'))(model.parameters(),\n",
    "                                                                    lr=params.get('learning_rate'),\n",
    "                                                                    weight_decay=params.get('weight_decay'))\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "torchinfo.summary(model, input_size=(params.get('batch_size'), 22, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cb3bba-c33d-4217-97b7-ec6fd4aeb0e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_accuracies, val_accuracies = utils.train_model(model=model,\n",
    "                                                     criterion=criterion,\n",
    "                                                     optimizer=optimizer,\n",
    "                                                     scheduler=scheduler,\n",
    "                                                     train_loader=train_loader,\n",
    "                                                     val_loader=val_loader,\n",
    "                                                     num_epochs=num_epochs,\n",
    "                                                     learning=False,\n",
    "                                                     device=device,\n",
    "                                                     trial=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b878385-24b8-4681-925c-d30cbe2a8bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num_epochs = num_epochs\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cefe38-3115-455f-8f18-3b6d729a7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "utils.test_model(model, test_loader)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da2aab9-2a95-481a-b414-520e260c5f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa32879-82cd-426e-b0fc-388ce8af09fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21cb73-1ed3-4685-b439-68fe11c0bc74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (linux-venv)",
   "language": "python",
   "name": "linux-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
