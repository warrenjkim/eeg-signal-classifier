{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a9d486-f433-4c2c-95a6-f49fb52f8eea",
   "metadata": {},
   "source": [
    "# Imports & Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec5cf7a6-73a8-4bc4-b3a1-76e82f9ee8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "from tqdm import tqdm\n",
    "from skorch.helper import predefined_split\n",
    "import copy\n",
    "\n",
    "from skorch.callbacks import LRScheduler\n",
    "\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "np.int = int\n",
    "np.bool = bool\n",
    "np.object = object\n",
    "from braindecode.preprocessing import (\n",
    "    exponential_moving_standardize,\n",
    "    preprocess,\n",
    "    Preprocessor,\n",
    "    create_fixed_length_windows\n",
    ")\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet, EEGConformer\n",
    "from braindecode import EEGClassifier\n",
    "from braindecode.datasets import BaseDataset, BaseConcatDataset\n",
    "\n",
    "\n",
    "from braindecode.augmentation import (\n",
    "    FTSurrogate,\n",
    "    SmoothTimeMask,\n",
    "    ChannelsDropout,\n",
    "    AugmentedDataLoader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e09bf3e-c977-433e-8ba9-ca8226076eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "  device = torch.device('mps')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922d1ccf-8bdf-42ba-b05f-3f8edc0713fa",
   "metadata": {},
   "source": [
    "# Important Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23263790-bc14-40ef-af91-2e215bd74f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "set_random_seeds(seed, str(device)=='cuda')\n",
    "num_channels = 22\n",
    "num_classes = 4\n",
    "ch_names = [str(i) for i in range(num_channels)]\n",
    "classes = list(range(num_classes))\n",
    "input_window_samples = 400\n",
    "lr = 0.0625 * 0.01\n",
    "weight_decay = 0\n",
    "batch_size = 64\n",
    "n_epochs = 15 # 50\n",
    "folds = 10\n",
    "sfreq = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b31d24a-81b5-4e98-bddd-777f1e93b5a5",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6145833a-e82d-4cd3-909d-36f81321ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_valid = np.load(\"./project_data/X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"./project_data/y_train_valid.npy\") - 769\n",
    "\n",
    "X_test = np.load(\"./project_data/X_test.npy\")\n",
    "y_test = np.load(\"./project_data/y_test.npy\") - 769\n",
    "\n",
    "person_train_valid = np.load(\"./project_data/person_train_valid.npy\")\n",
    "person_test = np.load(\"./project_data/person_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0786b80a-af78-4792-8348-781760fe31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(X,\n",
    "              y,\n",
    "              sub_sample,\n",
    "              average,\n",
    "              noise,\n",
    "              p_channel_dropoup=0,\n",
    "              smooth_time_mask=False,\n",
    "              mask_size=0,\n",
    "              time_shift=0,\n",
    "              clipping_max=800,\n",
    "              noise_stdev=0.5):\n",
    "\n",
    "    total_X = None\n",
    "    total_y = None\n",
    "    X = X[:,:,0:clipping_max]\n",
    "    print('Shape of X after trimming: {X.shape}')\n",
    "    X_max, _ = torch.max(X.view(X.size(0), X.size(1), -1, sub_sample), axis=3)\n",
    "\n",
    "    total_X = X_max\n",
    "    total_y = y\n",
    "    print('Shape of X after maxpooling:',total_X.shape)\n",
    "\n",
    "    X_average = torch.mean(X.view(X.size(0), X.size(1), -1, average), axis=3)\n",
    "    X_average = X_average + torch.normal(0.0, noise_stdev, X_average.shape)\n",
    "\n",
    "    total_X = torch.cat((total_X, X_average), dim=0)\n",
    "    total_y = torch.cat((total_y, y))\n",
    "    print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
    "\n",
    "    for i in range(sub_sample):\n",
    "        X_subsample = X[:, :, i::sub_sample] + \\\n",
    "                            (torch.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
    "        total_X = torch.cat((total_X, X_subsample), dim=0)\n",
    "        print(total_y.view(-1,1).shape)\n",
    "        print(y.view(-1,1).shape)\n",
    "        total_y = torch.cat((total_y, y))\n",
    "\n",
    "    print('Shape of X after subsampling and concatenating:',total_X.shape)\n",
    "    print('Shape of Y:',total_y.shape)\n",
    "\n",
    "    if p_channel_dropout != 0:\n",
    "        mask = (torch.rand(total_X.shape[0], total_X.shape[1]) >= p_channel_dropout).unsqueeze(2)\n",
    "        X_dropout = mask * total_X\n",
    "        total_X = torch.cat((total_X, X_dropout))\n",
    "        total_y = torch.cat((total_y, total_y))\n",
    "\n",
    "        print(f'Shape of X after channel dropout {total_X.shape}')\n",
    "        print(f'Shape of Y: {total_y.shape}')\n",
    "\n",
    "    if smooth_time_mask:\n",
    "        copy_X = copy.deepcopy(total_X)\n",
    "        starts = ((torch.rand(copy_X.shape[0])*(copy_X.shape[2]-mask_size-1))).round()\n",
    "        for idx, m in enumerate(copy_X):\n",
    "            start = int(starts[idx])\n",
    "            end = start+mask_size\n",
    "            m[:,start:end] = 0\n",
    "        total_X = torch.cat((total_X, copy_X))\n",
    "        total_y = torch.cat((total_y, total_y))\n",
    "        \n",
    "        print(f'Shape of X after smooth time mask {total_X.shape}')\n",
    "        print(f'Shape of Y: {total_y.shape}')\n",
    "\n",
    "    if time_shift != 0:\n",
    "        time_shift_X = copy.deepcopy(total_X)\n",
    "        shifts = np.random.randint(low=-time_shift, high=time_shift+1, size=(total_X.shape[0],))\n",
    "        time_shift_X = torch.Tensor(np.array([torch.roll(elem, shift, 1) for elem, shift in zip(time_shift_X, shifts)]))\n",
    "        total_X = torch.cat((total_X, time_shift_X))\n",
    "        total_y = torch.cat((total_y, total_y))\n",
    "        \n",
    "        print(f'Shape of X after time_shift {total_X.shape}')\n",
    "        print(f'Shape of Y: {total_y.shape}')\n",
    "\n",
    "    return total_X,total_y\n",
    "\n",
    "def test_data_prep(X):\n",
    "    total_X = None\n",
    "    X = X[:,:,0:800]\n",
    "    print('Shape of X after trimming:', X.shape)\n",
    "    X_max, _ = torch.max(X.view(X.size(0), X.size(1), -1, 2), axis=3)\n",
    "    total_X = X_max\n",
    "    print('Shape of X after maxpooling:',total_X.shape)\n",
    "    return total_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d884594-e18a-41c3-bdc9-a187ef7c74af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOME torch.Size([2115, 22, 1000])\n",
      "Prepping Training Data\n",
      "Shape of X after trimming: {X.shape}\n",
      "Shape of X after maxpooling: torch.Size([1903, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([3806, 22, 400])\n",
      "torch.Size([3806, 1])\n",
      "torch.Size([1903, 1])\n",
      "torch.Size([5709, 1])\n",
      "torch.Size([1903, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([7612, 22, 400])\n",
      "Shape of Y: torch.Size([7612])\n",
      "Shape of X after channel dropout torch.Size([15224, 22, 400])\n",
      "Shape of Y: torch.Size([15224])\n",
      "Shape of X after time_shift torch.Size([30448, 22, 400])\n",
      "Shape of Y: torch.Size([30448])\n",
      "\n",
      "Prepping Validation Data\n",
      "Shape of X after trimming: {X.shape}\n",
      "Shape of X after maxpooling: torch.Size([212, 22, 400])\n",
      "Shape of X after averaging+noise and concatenating: torch.Size([424, 22, 400])\n",
      "torch.Size([424, 1])\n",
      "torch.Size([212, 1])\n",
      "torch.Size([636, 1])\n",
      "torch.Size([212, 1])\n",
      "Shape of X after subsampling and concatenating: torch.Size([848, 22, 400])\n",
      "Shape of Y: torch.Size([848])\n",
      "Shape of X after channel dropout torch.Size([1696, 22, 400])\n",
      "Shape of Y: torch.Size([1696])\n",
      "Shape of X after time_shift torch.Size([3392, 22, 400])\n",
      "Shape of Y: torch.Size([3392])\n",
      "\n",
      "Prepping Test Data\n",
      "Shape of X after trimming: torch.Size([443, 22, 800])\n",
      "Shape of X after maxpooling: torch.Size([443, 22, 400])\n"
     ]
    }
   ],
   "source": [
    "indices = np.random.permutation(X_train_valid.shape[0])\n",
    "split_idx = int(X_train_valid.shape[0] * ((folds-1)/folds))\n",
    "\n",
    "folds = 10\n",
    "split_seed = 1\n",
    "\n",
    "subsample = 2\n",
    "average = 2\n",
    "noise = True\n",
    "p_channel_dropout = 0.01\n",
    "smooth_time_mask = False\n",
    "mask_size = 120\n",
    "time_shift = 30\n",
    "clipping_max = 800\n",
    "noise_stdev = 0.16 # 0.5\n",
    "\n",
    "X_train_valid = torch.Tensor(X_train_valid)\n",
    "y_train_valid = torch.Tensor(y_train_valid)\n",
    "\n",
    "print(f'SOME {X_train_valid.shape}')\n",
    "indices = torch.randperm(X_train_valid.shape[0])\n",
    "split_idx = int(X_train_valid.shape[0] * ((folds-1)/folds))\n",
    "X_train, X_valid = X_train_valid[indices[:split_idx]], X_train_valid[indices[split_idx:]]\n",
    "y_train, y_valid = y_train_valid[indices[:split_idx]], y_train_valid[indices[split_idx:]]\n",
    "X_test, y_test = torch.Tensor(X_test), torch.Tensor(y_test)\n",
    "\n",
    "print('Prepping Training Data')\n",
    "X_train, y_train = data_prep(X_train, y_train, subsample, average, noise, p_channel_dropout, smooth_time_mask, mask_size,\n",
    "                            time_shift, clipping_max, noise_stdev)\n",
    "print('\\nPrepping Validation Data')\n",
    "X_valid, y_valid = data_prep(X_valid, y_valid, subsample, average, noise, p_channel_dropout, smooth_time_mask, mask_size,\n",
    "                            time_shift, clipping_max, noise_stdev)\n",
    "print('\\nPrepping Test Data')\n",
    "X_test = test_data_prep(X_test)\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_valid, y_valid = np.array(X_valid), np.array(y_valid)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2717105-3466-4680-be7d-1ea7c4841495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_from_X_y(X, y, drop_last_window, sfreq, ch_names):\n",
    "  n_samples_per_x = []\n",
    "  base_datasets = []\n",
    "  for x, target in zip(X, y):\n",
    "    n_samples_per_x.append(x.shape[1])\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq) # , ch_types=ch_types\n",
    "    raw = mne.io.RawArray(x, info, verbose=False)\n",
    "    base_dataset = BaseDataset(raw, pd.Series({\"target\": target}),\n",
    "                               target_name=\"target\")\n",
    "    base_datasets.append(base_dataset)\n",
    "  base_datasets = BaseConcatDataset(base_datasets)\n",
    "  if not len(np.unique(n_samples_per_x)) == 1:\n",
    "    raise ValueError(\"if 'window_size_samples' and \"\n",
    "                      \"'window_stride_samples' are None, \"\n",
    "                      \"all trials have to have the same length\")\n",
    "  window_size_samples = n_samples_per_x[0]\n",
    "  window_stride_samples = n_samples_per_x[0]\n",
    "  windows_datasets = create_fixed_length_windows(\n",
    "    base_datasets,\n",
    "    start_offset_samples=0,\n",
    "    stop_offset_samples=None,\n",
    "    window_size_samples=window_size_samples,\n",
    "    window_stride_samples=window_stride_samples,\n",
    "    drop_last_window=drop_last_window\n",
    "  )\n",
    "  return windows_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa04ae-4975-4413-b309-26e142f13cb9",
   "metadata": {},
   "source": [
    "## Create Braindecode Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc82a170-2d7e-447d-b8b0-2ec87a550580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE TRAIN\n",
      "DONE VALID\n",
      "DONE TEST\n"
     ]
    }
   ],
   "source": [
    "train_dataset = create_from_X_y(X_train, y_train, False, sfreq, ch_names=ch_names);\n",
    "print('DONE TRAIN')\n",
    "valid_dataset = create_from_X_y(X_valid, y_valid, False, sfreq, ch_names=ch_names);\n",
    "print('DONE VALID')\n",
    "test_dataset = create_from_X_y(X_test, y_test, False, sfreq, ch_names=ch_names);\n",
    "print('DONE TEST')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d3f6a-5a24-4f4b-95a2-f0b97945a82d",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c69ec8-cdb8-43b4-a85c-ecda46e7d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cut_hz = 4.0  # low cut frequency for filtering\n",
    "high_cut_hz = 38.0  # high cut frequency for filtering\n",
    "factor_new = 1e-3\n",
    "init_block_size = 400\n",
    "\n",
    "preprocessors = [\n",
    "    Preprocessor(\"filter\", l_freq=low_cut_hz, h_freq=high_cut_hz, picks=ch_names, verbose=False),  # Bandpass filter\n",
    "    Preprocessor(\n",
    "        exponential_moving_standardize,  # Exponential moving standardization\n",
    "        factor_new=factor_new,\n",
    "        init_block_size=init_block_size,\n",
    "        picks=ch_names,\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Preprocess the data\n",
    "# preprocess(train_dataset, preprocessors)\n",
    "# preprocess(valid_dataset, preprocessors)\n",
    "# preprocess(test_dataset, preprocessors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38679e12-8c3d-472f-bad3-a021063ea245",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e80f318-8af6-4c1b-807a-5f47074e800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels_dropout = ChannelsDropout(\n",
    "#     probability=0.5,\n",
    "#     p_drop=1\n",
    "# )\n",
    "\n",
    "# smooth_time_mask = SmoothTimeMask(\n",
    "#     probability=0.5,\n",
    "#     mask_len_samples=300\n",
    "# )\n",
    "\n",
    "# transforms = [smooth_time_mask, channels_dropout]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252226af-ae64-457a-9155-ec99ef4e457e",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24a37601-7c21-46cb-8ab3-c83b955631c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "============================================================================================================================================\n",
      "ShallowFBCSPNet (ShallowFBCSPNet)        [1, 22, 400]              [1, 4]                    --                        --\n",
      "├─Ensure4d (ensuredims): 1-1             [1, 22, 400]              [1, 22, 400, 1]           --                        --\n",
      "├─Rearrange (dimshuffle): 1-2            [1, 22, 400, 1]           [1, 1, 400, 22]           --                        --\n",
      "├─CombinedConv (conv_time_spat): 1-3     [1, 1, 400, 22]           [1, 40, 376, 1]           36,240                    --\n",
      "├─BatchNorm2d (bnorm): 1-4               [1, 40, 376, 1]           [1, 40, 376, 1]           80                        --\n",
      "├─Expression (conv_nonlin_exp): 1-5      [1, 40, 376, 1]           [1, 40, 376, 1]           --                        --\n",
      "├─AvgPool2d (pool): 1-6                  [1, 40, 376, 1]           [1, 40, 21, 1]            --                        [75, 1]\n",
      "├─Expression (pool_nonlin_exp): 1-7      [1, 40, 21, 1]            [1, 40, 21, 1]            --                        --\n",
      "├─Dropout (drop): 1-8                    [1, 40, 21, 1]            [1, 40, 21, 1]            --                        --\n",
      "├─Sequential (final_layer): 1-9          [1, 40, 21, 1]            [1, 4]                    --                        --\n",
      "│    └─Conv2d (conv_classifier): 2-1     [1, 40, 21, 1]            [1, 4, 1, 1]              3,364                     [21, 1]\n",
      "│    └─LogSoftmax (logsoftmax): 2-2      [1, 4, 1, 1]              [1, 4, 1, 1]              --                        --\n",
      "│    └─Expression (squeeze): 2-3         [1, 4, 1, 1]              [1, 4]                    --                        --\n",
      "============================================================================================================================================\n",
      "Total params: 39,684\n",
      "Trainable params: 39,684\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 0.00\n",
      "============================================================================================================================================\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 0.12\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.17\n",
      "============================================================================================================================================\n",
      "TRAIN LENGTH: 30448\n",
      "VALID LENGTH: 3392\n",
      "TEST LENGTH: 443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klkelley/UCLA/w_24/ece_c147/project/local_runtime/lib/python3.12/site-packages/braindecode/models/base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    }
   ],
   "source": [
    "model = ShallowFBCSPNet(\n",
    "    num_channels,\n",
    "    num_classes,\n",
    "    n_times=input_window_samples,\n",
    "    final_conv_length=\"auto\",\n",
    ")\n",
    "print(model)\n",
    "model.to(device)\n",
    "\n",
    "print(f'TRAIN LENGTH: {len(train_dataset)}')\n",
    "print(f'VALID LENGTH: {len(valid_dataset)}')\n",
    "print(f'TEST LENGTH: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0fa34a-5059-4f91-99b7-e26ce0688e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr      dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  -------\n",
      "      1            \u001b[36m0.6791\u001b[0m        \u001b[32m1.2530\u001b[0m       \u001b[35m0.5825\u001b[0m            \u001b[31m0.5825\u001b[0m        \u001b[94m0.9553\u001b[0m  0.0006  27.4831\n",
      "      2            \u001b[36m0.7573\u001b[0m        \u001b[32m0.8677\u001b[0m       \u001b[35m0.6624\u001b[0m            \u001b[31m0.6624\u001b[0m        \u001b[94m0.8642\u001b[0m  0.0006  19.7449\n",
      "      3            \u001b[36m0.8376\u001b[0m        \u001b[32m0.7099\u001b[0m       \u001b[35m0.6787\u001b[0m            \u001b[31m0.6787\u001b[0m        \u001b[94m0.8385\u001b[0m  0.0006  19.7757\n",
      "      4            \u001b[36m0.8512\u001b[0m        \u001b[32m0.6139\u001b[0m       0.6754            0.6754        0.8632  0.0006  20.3260\n"
     ]
    }
   ],
   "source": [
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    # iterator_train=AugmentedDataLoader,\n",
    "    # iterator_train__transforms=transforms,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=predefined_split(valid_dataset),\n",
    "    optimizer__lr=lr,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\",\n",
    "        (\"lr_scheduler\", LRScheduler(\"CosineAnnealingLR\", T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    "    classes=classes,\n",
    "    max_epochs=n_epochs,\n",
    ")\n",
    "clf.fit(train_dataset, y=None)\n",
    "\n",
    "# evaluated the model after training\n",
    "y_test = test_dataset.get_metadata().target\n",
    "test_acc = clf.score(test_dataset, y=y_test)\n",
    "print(f\"Test acc: {(test_acc * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cab02c-70e0-47b6-b00f-4a577a39ec28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
